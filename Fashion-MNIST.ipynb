{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        #TODO\n",
    "        #implement the forward pass\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Network(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=192, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (out): Linear(in_features=60, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "network = Network()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=192, out_features=120, bias=True)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=120, out_features=60, bias=True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=60, out_features=10, bias=True)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[[[-0.1033,  0.0622,  0.1497, -0.1884,  0.0516],\n          [-0.0554, -0.1546, -0.1449, -0.0084,  0.0269],\n          [ 0.0131,  0.1053, -0.1265,  0.0973, -0.0023],\n          [-0.1985,  0.0222,  0.1934,  0.0588, -0.1528],\n          [-0.0476,  0.1769,  0.0611, -0.0675,  0.1164]]],\n\n\n        [[[ 0.1069,  0.0623, -0.0553,  0.0619, -0.0700],\n          [-0.0465, -0.1585,  0.1221, -0.1780,  0.1015],\n          [ 0.0815,  0.1276, -0.1221,  0.0244, -0.1538],\n          [ 0.0128,  0.1550,  0.0725, -0.0350,  0.1404],\n          [-0.0810, -0.0566, -0.1441,  0.1195,  0.1723]]],\n\n\n        [[[-0.0993,  0.0450,  0.0268, -0.0524,  0.1701],\n          [ 0.0299,  0.0774, -0.1472, -0.0541, -0.1652],\n          [ 0.1260, -0.0201, -0.0414,  0.1410,  0.0355],\n          [-0.1487,  0.1218,  0.0922,  0.1194,  0.1516],\n          [ 0.0173, -0.0169, -0.1402, -0.0053, -0.1092]]],\n\n\n        [[[ 0.1804,  0.1291,  0.1026,  0.1845,  0.0967],\n          [-0.1591, -0.0484,  0.1992, -0.1671, -0.0646],\n          [-0.1372, -0.1330,  0.1733,  0.0353,  0.0560],\n          [ 0.0579, -0.0185,  0.1478, -0.0827, -0.0054],\n          [ 0.1772,  0.0412, -0.0587,  0.1506, -0.1276]]],\n\n\n        [[[ 0.0918,  0.1610,  0.0829, -0.0864,  0.1785],\n          [ 0.1842, -0.1250,  0.1494, -0.1459,  0.1914],\n          [ 0.0526, -0.1671, -0.0668, -0.1650,  0.1328],\n          [-0.0043, -0.0924, -0.0593,  0.0187,  0.0493],\n          [-0.0143,  0.0550, -0.0711, -0.0517,  0.0529]]],\n\n\n        [[[ 0.0446,  0.0068,  0.1121, -0.0283,  0.0893],\n          [-0.1530, -0.0383,  0.1382, -0.0495,  0.1912],\n          [-0.1051,  0.0756,  0.1102, -0.0399, -0.0392],\n          [ 0.1431,  0.0723,  0.0226,  0.1672,  0.1984],\n          [-0.0235,  0.1888, -0.1760,  0.1679, -0.1509]]]], requires_grad=True)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is from OOP from Pytorch with hidden Weights. This is updated when learning, when the loss function is minimized. The Parameter class extends torch.Tensor\n",
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 1, 5, 5])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first rank => # of filters\n",
    "#2nd rank => depth of each filter or # of input channels\n",
    "#3rd and 4th is the height and width of the filter\n",
    "network.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 6, 5, 5])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 5, 5])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is how you single out the Weight Tensor\n",
    "network.conv2.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([120, 192])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2 tensors of linear layer\n",
    "#Height is the output feature of the prevous Tensor\n",
    "#Width is the number of input features\n",
    "#This is a Weight Matrix. Weight Matrix * Input = Ouput.\n",
    "network.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([60, 120])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 60])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.out.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([1., 2., 3., 4.])\n"
    }
   ],
   "source": [
    "in_features = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3., 4.],\n        [2., 3., 4., 5.],\n        [3., 4., 5., 6.]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,6]\n",
    "], dtype=torch.float32)\n",
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([30., 40., 50.])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([6, 1, 5, 5])\ntorch.Size([6])\ntorch.Size([12, 6, 5, 5])\ntorch.Size([12])\ntorch.Size([120, 192])\ntorch.Size([120])\ntorch.Size([60, 120])\ntorch.Size([60])\ntorch.Size([10, 60])\ntorch.Size([10])\n"
    }
   ],
   "source": [
    "for param in network.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "conv1.weight \t\t torch.Size([6, 1, 5, 5])\nconv1.bias \t\t torch.Size([6])\nconv2.weight \t\t torch.Size([12, 6, 5, 5])\nconv2.bias \t\t torch.Size([12])\nfc1.weight \t\t torch.Size([120, 192])\nfc1.bias \t\t torch.Size([120])\nfc2.weight \t\t torch.Size([60, 120])\nfc2.bias \t\t torch.Size([60])\nout.weight \t\t torch.Size([10, 60])\nout.bias \t\t torch.Size([10])\n"
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  }
 ]
}